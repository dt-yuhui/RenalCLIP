{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32ad019-1fda-4121-a7f5-ea95806d82a2",
   "metadata": {},
   "source": [
    "# offline save prompts for zeroshot task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595c67e-7666-48ac-9c5d-0430be019fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "ZEROSHOT_BASE_DIR = '/cpfs01/projects-HDD/cfff-bb5d866c17c2_HDD/taoyuhui/RenalCLIP/RenalCLIP/zero_shot'\n",
    "\n",
    "#  all templates and attribute candidates are saved in zeroshot_prompt.json\n",
    "json_file_path = os.path.join(ZEROSHOT_BASE_DIR, 'zeroshot_prompt.json')\n",
    "\n",
    "try:\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: JSON file not found at {json_file_path}. Please ensure it exists.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from {json_file_path}. Check file format.\")\n",
    "    exit()\n",
    "\n",
    "templates = data[\"templates\"]\n",
    "attributes = data[\"attributes\"]\n",
    "\n",
    "# Construct a dictionary for task-template-label matching.\n",
    "# The structure of this dictionary will be:\n",
    "# {\n",
    "#   \"TASK_NAME\": {\n",
    "#     \"LABEL_VALUE\": [\n",
    "#       \"template1_desc1\", \"template1_desc2\", \"template1_desc3\",\n",
    "#       \"template2_desc1\", \"template2_desc2\", \"template2_desc3\",\n",
    "#       ...\n",
    "#     ]\n",
    "#   }\n",
    "# }\n",
    "result_dict = {}\n",
    "\n",
    "for task, labels in attributes.items(): # Iterate through each task, such as \"IC\", and \"BMC\".\n",
    "    task_dict = {}\n",
    "    for label, descriptions_list in labels.items(): # Iterate through each label value, such as \"0\" and \"1\".\n",
    "        # descriptions_list is now a list containing all the description candidates for this label\n",
    "        \n",
    "        filled_texts_for_label = []\n",
    "        for template in templates: # Iterate through all the templates\n",
    "            for description in descriptions_list: # Iterate through all the description candidates for the current label\n",
    "                # Replace the placeholders in the template with the current description\n",
    "                filled_text = template.replace(\"____\", description)\n",
    "                filled_texts_for_label.append(filled_text)\n",
    "        \n",
    "        task_dict[label] = filled_texts_for_label\n",
    "    result_dict[task] = task_dict\n",
    "\n",
    "# Save the generated result_dict to another JSON file\n",
    "output_file = os.path.join(ZEROSHOT_BASE_DIR, 'expanded_zeroshot_prompts.json')\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(result_dict, outfile, indent=4, ensure_ascii=False)\n",
    "print(f\"Expanded prompts 已成功保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1f0bd-018d-4bf2-a055-37cbdd1a1a15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# offline save embeddings of prompts for llm2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458dde3b-704c-4cbb-892f-b5b2dda879df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from llm2vec import LLM2Vec\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700dfcf9-62e2-4284-bfc1-1d4fc4f6ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PRETRAINED_DIR = fr\"/cpfs01/projects-HDD/cfff-bb5d866c17c2_HDD/taoyuhui/RenalCLIP/pretrained_models/language_family\"\n",
    "llm2vec_base_name = \"hub/Meta-Llama-3-8B-Instruct-radiology-ext-long\"\n",
    "llm2vec_peft_name = \"hub/Meta-Llama-3-8B-Instruct-radiology-simcse/checkpoint-1000\"\n",
    "\n",
    "l2v = LLM2Vec.from_pretrained(\n",
    "    os.path.join(TEXT_PRETRAINED_DIR, llm2vec_base_name),\n",
    "    peft_model_name_or_path=os.path.join(TEXT_PRETRAINED_DIR, llm2vec_peft_name),\n",
    "    device_map=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    local_files_only=True,\n",
    "    pooling_mode=\"mean\",\n",
    "    max_length=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9143a-21a9-4037-bf0f-30bf010585a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_before_align = False\n",
    "\n",
    "prefix = \"templates_with_avg\" if avg_before_align else \"templates_wo_avg\"\n",
    "ZEROSHOT_BASE_DIR = '/cpfs01/projects-HDD/cfff-bb5d866c17c2_HDD/taoyuhui/RenalCLIP/RenalCLIP/zero_shot'\n",
    "TEXT_EMBEDDINGS_DIR = fr\"/cpfs01/projects-SSD/cfff-bb5d866c17c2_SSD/public/RenalCLIP/zeroshot_text_embeddings/llm2vec-rad\"\n",
    "os.makedirs(TEXT_EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "# load Zero-shot prompts\n",
    "zeroshot_file_path = os.path.join(ZEROSHOT_BASE_DIR, 'expanded_zeroshot_prompts.json')\n",
    "with open(zeroshot_file_path, 'r') as json_file:\n",
    "    prompt_data = json.load(json_file)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for task_name, labels in prompt_data.items():\n",
    "        print(f\"Processing task: {task_name}\")\n",
    "        task_dir = os.path.join(TEXT_EMBEDDINGS_DIR, prefix, task_name)\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "\n",
    "        for label, texts in labels.items():\n",
    "            if avg_before_align:\n",
    "                # Before performing zero-shot inference, save the averaged embeddings from multiple templates\n",
    "                template_embeddings = l2v.encode(texts, show_progress_bar=False).float()  # shape: (num_templates, embedding_dim)\n",
    "                template_embeddings = template_embeddings / template_embeddings.norm(dim=-1, keepdim=True) # norm\n",
    "                avg_embedding = template_embeddings.mean(dim=0, keepdim=True) # shape: (1, embedding_dim)\n",
    "                avg_embedding = avg_embedding / avg_embedding.norm(dim=-1, keepdim=True) # norm\n",
    "                avg_embedding = avg_embedding.numpy()\n",
    "\n",
    "                embedding_file = os.path.join(task_dir, f\"{label}.npy\")\n",
    "                np.save(embedding_file, avg_embedding)\n",
    "            else:\n",
    "                # save each template embedding individually\n",
    "                template_embeddings = l2v.encode(texts, show_progress_bar=False).float()  # shape: (num_templates, embedding_dim)\n",
    "                template_embeddings = template_embeddings / template_embeddings.norm(dim=-1, keepdim=True) # norm\n",
    "                template_embeddings = template_embeddings.numpy()            \n",
    "\n",
    "                embedding_file = os.path.join(task_dir, f\"{label}.npy\")\n",
    "                np.save(embedding_file, template_embeddings)\n",
    "\n",
    "\n",
    "    print(\"All embeddings have been processed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
