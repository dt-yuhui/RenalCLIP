{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f993d2f-0188-41c4-aade-673791becf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from utils.util import *\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "CUSTOM_PRETRAINED_DIR = fr\"/cpfs01/projects-HDD/cfff-bb5d866c17c2_HDD/taoyuhui/RenalCLIP/clip_output\"\n",
    "from models.RenalModel import RenalModel\n",
    "from utils.parser import get_downstream_args_img\n",
    "from utils.data_util import custom_collate_fn_downstream_img\n",
    "from datasets.data_loader_RenalCLIP_downstream_img import DatasetRenalCLIPDownstreamImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7249b76-1270-48a9-ae5e-ef684c7349d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_encoder(args):\n",
    "    image_encoder = RenalModel(  \n",
    "                            mode='pretrain',\n",
    "                            pretrained_exp_name=args.pretrained_exp_name,\n",
    "                            pretrained_metric=args.pretrained_metric,\n",
    "                            model_type=args.model_type,\n",
    "                            logger=None,\n",
    "                            clip_output_dim=args.clip_output_dim,\n",
    "                            clip_hidden_dim=args.clip_hidden_dim,\n",
    "                            )\n",
    "\n",
    "    return image_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1f0bd-018d-4bf2-a055-37cbdd1a1a15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# offline save image embeddings of ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98a026-c349-4608-bc1f-3de8ef1fb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_downstream_args_img()\n",
    "args.img_encoder_type = 'cnn'\n",
    "args.pretrained_exp_name = 'RenalCLIP-image-encoder'\n",
    "\n",
    "args.pretrained_metric = 'acc'\n",
    "args.pre_processed_type = 'one_kidney_tc_v3'\n",
    "args.split_file_name = '/cpfs01/projects-HDD/cfff-bb5d866c17c2_HDD/taoyuhui/RenalCLIP/RenalCLIP/data/data_split_latest.json'\n",
    "args.cropsize_3d = 128\n",
    "args.crop_slices = 32\n",
    "args.in_features = 512\n",
    "args.clip_output_dim = 4096\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_encoder = get_image_encoder(args)\n",
    "image_encoder = image_encoder.to(device)\n",
    "image_encoder.eval()\n",
    "\n",
    "output_base_dir = \"/cpfs01/projects-SSD/cfff-bb5d866c17c2_SSD/public/RenalCLIP/image_embeddings_demo\"\n",
    "model_name = 'ours'\n",
    "\n",
    "print(f\"Saving image embeddings for model '{model_name}' to: {output_base_dir}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    hospitals = [\"internal\", \"external\", \"TCIA\"]\n",
    "    for hospital in hospitals:\n",
    "        dataset = DatasetRenalCLIPDownstreamImg(args, split='test', hospital=hospital)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            batch_size=args.batch_size,\n",
    "            num_workers=args.num_workers,\n",
    "            collate_fn=custom_collate_fn_downstream_img(args),\n",
    "        )\n",
    "\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Processing and Saving Image Features\")):\n",
    "\n",
    "            images = batch['imgs'].to(device)\n",
    "            patient_ids = batch['patients']\n",
    "\n",
    "            img_feats = image_encoder(images).float()\n",
    "            img_feats = image_encoder.image_encoder.global_embedding(img_feats)\n",
    "\n",
    "            # normalize\n",
    "            img_feats = img_feats / img_feats.norm(dim=-1, keepdim=True)\n",
    "            img_feats_np = img_feats.cpu().numpy()\n",
    "\n",
    "            for j, patient_id in enumerate(patient_ids):\n",
    "\n",
    "                patient_output_dir = os.path.join(output_base_dir, model_name, patient_id)\n",
    "\n",
    "                os.makedirs(patient_output_dir, exist_ok=True)\n",
    "\n",
    "                save_path = os.path.join(patient_output_dir, 'image_embedding.npy')\n",
    "\n",
    "                np.save(save_path, img_feats_np[j])\n",
    "\n",
    "print(\"所有图片特征已成功保存到磁盘！\")\n",
    "print(f\"特征保存根目录: {output_base_dir}/{model_name}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
